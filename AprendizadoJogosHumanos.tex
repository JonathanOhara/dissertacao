\chapter{Redes neurais e aprendizado de jogos com humanos}
\label{chap:aprendizadoJogosComHumanos}

\section{Introdução}

Nesse capítulo vamos discutir sobre aprendizagem de máquina e as tentativas de aprender com humanos. O capítulo está organizado da seguinte forma: primeiro, na seção \ref{sec:aprendizado} será falado sobre aprendizado e, o que isso representa. Na seção \ref{sec:redesNeurais} será apresentado sobre redes neurais. Na seção \ref{sec:implementacoesRN} é apresentado algumas das principais técnicas de redes neurais. Na seção \ref{sec:neuroevolucao} será apresentado o algoritmo de neuroevolução. Na seção \ref{sec:aprendizadoComHumanos} será visto como essas técnicas são aplicadas para aprender contra humanos. Finalmente, na seção \ref{sec:conclusaoAprendizadoJogosComHumanos}, são apresentadas as consideração finais deste capítulo.

\section{Aprendizagem}
\label{sec:aprendizado}

Um dos processos mais naturais e comuns dos seres humanos é o processo de aprender. Segundo \cite{holt2012psychology} existem duas definições para aprendizagem que geralmente são usadas por psicólogos: "a mudança relativamente permanente no comportamento devido à experiência passada" ou, "o processo pelo qual ocorrem mudanças relativamente permanentes no potencial comportamental como resultado da experiência". Já \cite{de2013learning} afirma que tais definições clássicas são problemáticas e define o processo de aprendizado como adaptação ontogenética, ou seja, como mudanças no comportamento de um organismo resulta de regularidades no ambiente do organismo. Esta definição funcional não só resolve os problemas de outras definições, mas também tem importantes vantagens para a pesquisa de aprendizagem cognitiva.

No trabalho de \cite{schunk1996learning}, a aprendizagem, na perspectiva filosófica, pode ser discutida sob o título de epistemologia, que se refere ao estudo da origem, natureza, limites e métodos de conhecimento. Ainda segundo o autor a origem do conhecimento é obtida de dois modos: 

\begin{itemize}

	\item \textbf{Racionalismo}. Refere-se à idéia de que o conhecimento é derivado da razão sem recorrer aos sentidos.
	
	\item \textbf{Empirismo}. No contraste ao racionalismo, o empirismo se refere a ideia que a experiência é a fonte de conhecimento.

\end{itemize}

Fora do campo de psicologia e filosofia pode-se encontrar outras definições para o aprendizado, como no trabalho de \cite{carbonell1983overview} que define a aprendizagem como um fenômeno de múltiplas faces. O proceso de aprendizado inclue a aquisição de novos conhecimentos, o desenvolvimento de habilidades motoras e coginitivas através de instruções ou práticas, a organização do conhecimento, e a descoberta de novos fatos e teorias através da observação e experimentação.

\subsection{Aprendizado de máquina}
\label{sec:minimax}

O aprendizado de máquina são modelos matemáticos para representar o processo de aprendizado com máquinas, entre outras palavras, o estudo do processo de aprendizado e a modelagem computacional desse processo define o aprendizado de máquina.

Segundo \cite{carbonell1983overview} o aprendizado de máquina é organizado em três amplos campos de pesquisa:

\begin{itemize}

	\item \textbf{Estudos orientados a tarefas}. Desenvolvimento e análise de sistemas de aprendizado em um predeterminado conjunto de tarefas.
	
	\item \textbf{Simulação cognitiva}. Investigação e simulação do processo de aprendizado humano.
	
	\item \textbf{Análise teórica}. Exploração teórica do espaço dos possíveis métodos de aprendizado e algoritmos indenpendentes do domínio da aplicação.

\end{itemize}

%http://stpk.cs.rtu.lv/sites/all/files/stpk/materiali/MI/Artificial%20Intelligence%20A%20Modern%20Approach.pdf%

Segundo \cite{russell1995modern} um agente que utiliza aprendizado de máquina pode ser descrito pelo seguinte diagrama da \ref{fig:modelLearningAgents}.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{figures/modelLearningAgents.pdf}
\caption[Modelo de agente com aprendizagem]{Modelo de agente com aprendizagem.}
\label{fig:modelLearningAgents}
\end{figure}

O \textbf{elemento de aprendizado} é responsável por ajustar a inteligência do agente. O elemento pega o conhecimento adquirido e um pouco do \textit{feedback} da performance do agente, e determina como o elemento de desempenho deverá ser modificado.

O \textbf{elemento de desempenho} avalia todas as entradas que recebe (sensores, aprendizado e gerador de problema) e escolhe a ação.

O componente \textbf{crítica} avalia quão bem o agente está desempenhando. A crítica aplica um padrão fixo de desempenho, isso é necessário porque as próprias percepções não fornecem nenhuma indicação do sucesso do agente.

Por último, o \textbf{gerador de problema} é responsável por sugerir ações que podem levar a novas experiências que tragam algo novo pro agente. Esse elemento faz com que o agente não fique transitando em um pequeno conjunto de ações julgadas como boas, e avalie outras ações que não foram exploradas ou que foram pouco exploradas.

É muito comum na literatura classificar aprendizado de máquina de acordo com a avaliação do \textit{feedback} que o agente faz. As classificações são:

\begin{itemize}

	\item \textbf{Aprendizagem supervisionada}. Em situação onde as entradas e saídas do componente são conhecidas (o elemento que fornece esse mapeamento de saída e entrada é chamado de professor).
	
	\item \textbf{Aprendizagem não supervisionada}. Situação onde a saída correta não é conhecida .
	
	\item \textbf{Aprendizagem por reforço}. Nessa abordagem cada ação escolhida pelo agente recebe um reforço ou punição porém, sem nunca falar qual é a ação correta ou a melhor ação.

\end{itemize}

\section{Redes Neurais}
\label{sec:redesNeurais}

Segundo \cite{koehn1994combining} as redes neurais foram inventadas no espírito de ser uma metáfora biológica. A metáfora biológica para redes neurais é o cérebro humano. Como o cérebro, esse modelo computacional consiste em pequenas unidades interconectadas. Essas unidades (ou nós) têm habilidades bem simples. Assim, a força desse modelo deriva da interação dessas unidades. Ela depende da sua estrutura (topologia) e suas conexões.

Uma rede neural é composta por um conjunto de nós, ou \textbf{unidades}, conectadas por \textbf{ligações}. Cada ligação tem um valor númerico chamado de \textbf{peso} associado a ele. Os pesos são o principal meio de armazenamento de longo prazo em redes neurais e, a aprendizagem geralmente ocorre através da atualização desses pesos. Algumas dessas unidades são conectadas com o ambiente externo, e pode ser desenhada como unidades de entrada ou saída. Os pesos são modificados para tentar trazer a relação de entrada e saída da rede seja ajustada de acordo com o ambiente (\cite{russell1995modern}).

\subsection{Implementações de redes neurais}
\label{sec:implementacoesRN}

Essas pequenas unidades, conexões e topologias podem ser comparadas a neurônios e sinapses. Redes neurais de apenas uma camada são chamadas de \textit{perceptron}. Segundo \cite{beiu2003survey} uma rede neural de \textit{perceptron} é composta por um grafo onde os nós são neurônios e as arestas são as sinapses. Essa rede tem alguns nós de entrada, e alguns (ao menos um) nós de saída.

Pelo fato de o \textit{perceptron} ter apenas uma camada ele se torna muito limitado para resolver diferentes tipos de problemas, ou seja, o percetron apenas resolve problemas linearmente separáveis. O modelo \textit{perceptron} de múltiplas camadas (do inglês multilayer perceptron - MLP) apresenta uma ou mais camadas chamadas de unidades escondidas.

\subsubsection{Perceptron}

A imagem ilustra \ref{fig:percetronModel} ilustra o funcionamento de um perceptron.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{figures/perceptron.pdf}
\caption[Perceptron]{\textit{Perceptron}.}
\label{fig:percetronModel}
\end{figure}

O modelo simples de \textit{perceptron} funciona com saídas binárias, sendo muito utilizado para reconhecimento de padrões, ele funciona da seguinte forma:

\begin{itemize}
	\item Uma vetor de entrada X, onde cada posição do vetor representa uma característica diferente da entrada.
	\item Uma vetor W chamado de vetor de pesos sinápticos, para cada característica de entrada um peso é associado. Nesse vetor ocorrerão ajustes de valor até que a saída fique correta.
	\item Bias (b) é um valor de polarização que permite mudar a função de ativação para a esquerda ou para a direita, ou seja, ela permite melhor espalhar os resultados que a função de ativação gera esse valor também é ajustado durante o aprendizado.
\end{itemize}

A saída do \textit{perceptron} pode ser definida pela seguinte equação:

\begin{equation}
y = \sigma( \displaystyle\sum_{j=1}^{n} w_j x_ij + b_i ),
\end{equation}

onde \textbf{y} é o valor de saída(0 ou 1), \textbf{$\sigma$} é a função de ativação. Retorna 1 para valores maiores que zero, e retorna 0 para valores menores ou iguais a zero e \textbf{n} é o tamanho do vetor de entrada.

Até que para todas as entradas, todas saídas estejam corretas o vetor W e o \textit{bias} são atualizados. Segundo \cite{estebon1997perceptrons} ajustando os pesos das conexões entre as camadas, a saída do \textit{perceptron} pode ser "treinada" para corresponder com a saída desejada. O treino é completo quando um conjunto de entradas passa pela rede e os resultados obtidos são os resultados desejados. Se existir alguma diferença entre a saída atual e a saída desejada, os pesos são ajustados na camada de adaptação para produzir um conjunto de saída mais próximo aos valores desejados.

A equação de treinamento (ajuste de pesos) pode ser escrita da seguinte forma:

\begin{equation}
w'_ij = w_ij + \alpha(t_j - e_j) \times x_ij,
\end{equation}

onde \textbf{$w'_ij$} é o novo valor do peso, \textbf{$w_ij$} é o valor atual do peso, \textbf{$\alpha$} taxa de aprendizagem onde $0 \leq \alpha \leq 1$. Valores baixos para $\alpha$ faz com que os pesos sejam ajustados suavemente. A variável \textbf{$t_j$} representa resultado esperado, \textbf{$e_j$} resultado atual e \textbf{$x_ij$} o valor de entrada.

O percetron resolve qualquer problema linearmente separável como calcular o "E" lógico de duas entradas. A imagem \ref{fig:perceptronE} mostra um plano cartersiano onde conseguimos com uma reta separar entradas cuja a saída é igual 0 das entradas cuja saída é igual a 1.

\begin{figure}[H]
\centering
\includegraphics[width=10cm]{figures/perceptronE.pdf}
\caption[Perceptron E lógico]{\textit{Perceptron} E lógico.}
\label{fig:perceptronE}
\end{figure}

Em casos onde não o problema não é linearmente separável o perceptron falha. Como mostra a imagem  \ref{fig:perceptronXOR} não é possível separar linearmente o problema do ou excluisivo (XOR).

\begin{figure}[H]
\centering
\includegraphics[width=10cm]{figures/perceptronXOR.pdf}
\caption[Perceptron XOR]{\textit{Perceptron} XOR.}
\label{fig:perceptronXOR}
\end{figure}

\subsubsection{Perceptron de múltiplas camadas}

Um \textit{perceptron} de múltiplas camadas modifica um pouco o desenho de como funciona o \textit{perceptron}. A imagem \ref{fig:multilayerperceptron} mostra como funciona o MLP. Conforme mostra na imagem, o MLP tem uma camada de entrada, uma ou mais camadas escondidas (a quantidade de neurônios nas camadas escondidas não precisa ser uniforme, ou seja, ter a quantidade de neurônios igual a camada de entrada/saída) e uma camada de saída.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{figures/multilayerPerceptron.pdf}
\caption[Perceptron de múltiplas camadas]{\textit{Perceptron} de múltiplas camadas.}
\label{fig:percetronModel}
\end{figure}

O MLP é uma rede fortemente conectada, ou seja, é uma rede onde as camadas estão em uma certa ordem e os neurônios de uma camada estimulam todos os neurônios da camada subsequente. Essas conexões são chamadas de \textit{feedfoward}.

O funcionamento do MLP é bem semelhante ao do \textit{perceptron}. O aloritmo de treino mais simples para MLP é chamado de retro-propagação. Essa equação pode ser escrita da seguinte maneira:

\begin{equation}
\delta w^k_ij = \eta \times \frac{\partial E}{\partial w^k_ij},
\end{equation}

onde \textbf{$k$} é a camada que está sendo atualizada, \textbf{$\eta$} é a taxa de aprendizado, \textbf{$\partial$} representa a derivada parcial, \textbf{$E$} representa o valor de erro.

O valor de erro é representado pela seguinte equação:

\begin{equation}
E = \frac{1}{2} \times \displaystyle\sum_{i}{} (d_i - y_i)^2,
\end{equation}

onde \textbf{$d_i$} é o valor desejado de saída e \textbf{$y_i$} é a saída obtida.

É possível resolver o problema do XOR utilizando um MLP simples com uma camada escondida. A ilustração \ref{fig:MLPXOR} mostra como ficaria a solução.

\begin{figure}[H]
\centering
\includegraphics[width=10cm]{figures/MLPXOR.pdf}
\caption[MLP XOR]{\textit{MLP} XOR.}
\label{fig:MLPXOR}
\end{figure}

\section{Algoritmos genéticos}

A primeira pesquisa na área de algoritmos genéticos foi feito por John Holland no livro \textit{Adaptation in Natural and Artificial Systems}. Segundo \cite{mitchell1995genetic} algoritmos genéticos(GA) é uma abstração da evolução biológica, onde move-se uma população de cromossomos (representando candidatos a soluções de um determinado problema) para uma nova população, usando "seleção"  junto com operadores baseados em genéticas para cruzamentos e mutação. 

Segundo \cite{485447} antes de aplicar o algoritmo genético, é necessário mapear qual será a arquitetura do cromossomo de modo que ele represente uma solução para o problema. Para usar o modo convencional do algoritmo genético com cromossomos de tamanhos fixos, é preciso:

\begin{itemize}
	\item Determinar o esquema de representação.
	\item Determinar como mensurar o \textit{fitness}. Segundo \cite{mitchell1995genetic} o \textit{fitness} é definido por uma função que atribui uma nota (\textit{fitness}) para cada cromossomo da população atual. O \textit{fitness} do cromossomo depende de quão bem o cromossomo resolve o problema.
	\item Determinar os parâmetros e variáveis para controlar o algoritmo.
	\item Determinar um modo de mostrar o resultado e um critério de parada para o algoritmo.
\end{itemize}

Segundo \cite{485447} O algoritmo evolutivo pode ser separados em três passos:

\begin{itemize}
	\item Randomicamente criar uma população inicial de cromossomos (soluções para o problema).
	\item Executar os seguintes sub-passos na população até que o critério de parada seja satisfeito:
		\subitem \textbf{1:} Determinar para cada indivíduo um \textit{fitness} através da função avaliadora de \textit{fitness}.
		\subitem \textbf{2:} Selecionar quais indivíduos passarão para a próxima geração por uma probabilidade baseada em seu \textit{fitness}. Aplicar na nova população de indivíduos as 3 seguintes operações genéticas: copiar um indivíduo para a nova população; criar dois novos indivíduos combinando seus cromossomos através de alguma operação de cruzamento (\textit{crossover}); fazer a mutação de algumas características de um cromossomo aleatoriamente.
	\item Pegar o melhor indivíduo já criado (aquele com melhor \textit{fitness}) para utilizar na resolução do problema.
\end{itemize}
 
O resultado de algoritmo genético muitas vezes não é o melhor resultado possível, porém gera um resultado excelente em cenários onde não se sabe como resolver um problema, ou em cenários onde a solução ótima demora muito tempo para ser calculada.

\section{Neuroevolução}

No trabalho \textit{Combining genetic algorithms and neural networks: The encoding problem} de \cite{koehn1994combining} é levantado a seguinte questão: Se ambas técnicas são autônomas, porque então combiná-las? Ainda segundo \cite{koehn1994combining} a resposta curta para essa questão diz que o problema de redes neurais é o número de parâmetros que precisam ser atribuídos antes de qualquer treino começar, nesse ponto entra o algoritmo genético. O autor do trabalho completa dizendo que a inspiração vem da natureza, o sucesso de um indivíduo não é determinado apenas pelo conhecimento e habilidades que ele ganha através da experiência, também depende de sua herança genética.

O trabalho de \cite{risi2014neuroevolution} define o algoritmo básico de neuroevolução da seguinte forma: uma população de genótipos que codificam redes neurais artificiais é evoluida para encontrar uma rede (pesos e/ou topologia) que resolvam um problema computactional. Normalmente cada genótipo é codificado em uma rede neural, que então é testada para uma específica tarefa por um determinado período de tempo. O desempenho ou \textit{fitness} da rede é guardado e, uma vez que o valores de \textit{fitness} para os genótipos da população são determinados, uma nova população é gerada pela alteração ligeira dos genótipos que codificam a rede neural artificial (mutação) ou pela combinação de vários genótipos (\textit{crossover}). Em geral, genótipos com alto \textit{fitness} tem uma alta chance de ser selecionado para reprodução e os seus descendentes substituem genótipos com valores de \textit{fitness} mais baixos, formando assim uma nova geração. 

Segundo \cite{miikkulainen2006computational} existem vários métodos para a evolução das redes neurais. A maneira mais direta é formar a codificação genética para a rede pela concatenação dos valores numéricos de seus pesos, e evoluir uma população de tais codificações usando \textit{crossover} e mutação. 

Embora esta abordagem padrão seja fácil de implementar e prática em muitos domínios, métodos mais sofisticados podem resolver problemas muito mais difíceis. Dois métodos bem comuns para evoluir redes neurais artificiais são eles, sub-populações forçadas (do inglês Enforced sub-populations - ESP) e neuroevolução de topologias de aumento (do inglês Neuroevolution of augmenting topologies - NEAT).

\subsection{ESP}

No ESP \cite{gomez1997incremental} a população consiste de neurônios individuais em vez de redes completas, e um subconjunto de neurônios são reunidos para formar uma rede completa. No entanto, o ESP aloca uma população separada para cada uma das unidades na rede, e um neurônio só pode ser recombinado com membros de sua própria subpopulação. Entre outras palavras, o foco dessa abordagem é a evolução dos neurônios ao invés das redes.

A imagem \ref{fig:espModel} esquematiza o modelo ESP. A população de neurônios é reunida em sub-populações mostrada na ilustração como círculos. E finalmente a rede neural é formada escolhendo aleatoriamente um neurônio de cada sub-população.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{figures/ESP.pdf}
\caption[Modelo ESP]{Modelo \textit{ESP}.}
\label{fig:espModel}
\end{figure}


\subsection{NEAT}

O NEAT baseia-se na ideia de evoluir a topologia de rede, ou seja, adicionando novos neurônios, conexões na rede neural artificial. Os autores \cite{stanley2003evolving} dizem que o espaço de parâmetros pesquisado no espaço de redes adaptativas (como as redes geradas pelo NEAT) é muito maior do que para redes estáticas (topologias que nunca mudam). Além dos pesos de conexão, vários parâmetros de aprendizado devem ser evoluídos para cada regra de aprendizado em cada conexão. Assim, é importante minimizar o número de conexões otimizadas pela evolução. Além disso, a topologia da rede tem de ser optimizada. É necessário ter conexões entre os nós \textit{corretos}, para que as conexões possam ser fortalecidas ou enfraquecidas para alterar a relação entre os conceitos computacionais que eles representam.


A imagem \ref{fig:neatModel} esquematiza o modelo NEAT. No exemplo cada gene contém uma conexão de neurônios (X,Y se refere a conexão do neurônio X com o Y), além da conexão é guardado o peso, o número acima do gene é chamado de \textbf{número de inovação}. Os genes com fundos de cor mais escura mostra que ele está desabilitado. Na evolução da parte superior da imagem é adicionado uma nova conexão (número de inovação 7), e na parte inferior da imagem mostra a adição de um novo nó (desabilitando o gene de número de inovação 3, e adicionando gene de número de inovação 7 e 8).


\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{figures/NEAT.pdf}
\caption[Modelo NEAT]{Modelo \textit{NEAT}.}
\label{fig:neatModel}
\end{figure}

\subsection{Vantagens e Desvntagens}

Segundo \cite{risi2014neuroevolution} existe uma série de motivos para usar a neuroevolução e alguns motivos onde utilizar neurovolução não é tão interessante. As principais vantagens de utilizá-la é:

\begin{itemize}

	\item \textbf{Performance para bater recordes}. Para alguns problemas, neuroevolução simplesmente fornece o melhor desempenho em concorrência com outros métodos de aprendizagem ("desempenho" é, naturalmente, definido de forma variada para diferentes problemas).
	
	\item \textbf{Ampla aplicabilidade}. Outro benefício da neuroevolução é que ela pode ser usado para tarefas de aprendizagem supervisionadas, não supervisionadas e reforçadas. Neuroevolução só requer algum tipo de avaliação numérica da qualidade das suas redes.

	\item \textbf{Escalabilidade}. Comparado com muitos outros tipos de aprendizado por reforço neuroevolução parece lidar muito bem com grandes espaços de ação/estado.
	
	\item \textbf{Diversidade}. A neuroevolução pode se basear na rica família de métodos de preservação da diversidade e métodos multiobjetivos que foram desenvolvidos dentro da comunidade de computação evolutiva.
	
	\item \textbf{Aprendizagem aberta}. Enquanto neuroevolução pode ser usado para aprendizado por reforço, pode-se argumentar que poderia ir além desta formulação relativamente restrita de aprendizagem de reforço. Em particular, nos casos em que a topologia da rede também evolui, a neuroevolução poderia, em princípio, apoiar a evolução aberta, onde o comportamento de complexidade arbitrária e sofisticação poderia emergir. Concretamente, os algoritmos de neuroevolução costumam procurar em um espaço muito grande.
	
	\item \textbf{Permitir novos tipos de jogos}. Em jogos que o jogador humano pode evoluir os seus personagens, os equipamentos de seus personagens, seu time e outras customizações, seria muito díficil resolver com os tradicionais métodos de aprendizado. Computação evolutiva aqui fornece qualidades exclusivas para o \textit{design} do jogo e, alguns projetos dependem especificamente da neuroevolução.
	
\end{itemize}

Em contrapartida também existe situações que neuroevolução não é tão interessante, seja pelos resultados esperados ou por ter outras técnicas que teriam melhor desempenho. O principal problemaé que as redes neurais evoluídas tendem a ter características de "caixa preta", o que significa que um humano não pode facilmente descobrir o que faz olhando para elas. Em jogos comerciais por exemplo, seria muito díficil predizer e/ou depurar uma determinada escolhada de um agente que utiliza neuroevolução.

No trabalho de \cite{evoltuinaryneuralnetworks} foi criado uma rede neuroevolutiva para jogar Reversi (jogo de tabuleiro), para isso, foi implementado uma população de 50 rede neurais evoluindo por 1000 gerações, para calcular o \textit{fitness} de cada rede neural a rede era submetida a 244 jogos contra um agente baseado em \textit{minimax}, a percentagem de vitória define o \textit{fitness} do indivíduo.

\subsection{Neuroevolução em jogos}



\section{Aprendizado com Humanos}
\label{sec:aprendizadoComHumanos}



\section{Considerações Finais}
\label{sec:conclusaoAprendizadoJogosComHumanos}



--------------------------------------------------------------------------------------